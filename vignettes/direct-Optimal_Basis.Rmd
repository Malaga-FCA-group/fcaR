---
title:  "Direct Optimal Basis"
author: "Nicolas Felipe Trujillo Montero"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Direct Optimal Basis}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE
)
```

# Introduction

This document is a Rmarkdown compiled file by the own Rstudio for seeing the two algorithms with a simple and didactic form that we are going to show.

These algorithms are based in the use of package fcaR to make Formal Concept Analysis (FCA). Thanks to this, we can find implications set analyzing from a dataframe. Once we found this set, we can use basic methods of simplifications to reduce the implication number of the set using canonical-basis, for example:

1.- We load the necessary libraries (`fcaR` and `Matrix`): 

```{r libraries}
library(usethis)
library(devtools)
library(fcaR)
library(Matrix)
devtools::load_all()
```

2.- We show the dataframe planets (presented in the vignette Implications.Rmd) incorporated in the package `fcaR` and the implications obtained:

```{r planets}
knitr::kable(planets, format = "html", booktabs = TRUE)
df <- planets
fc <- FormalContext$new(df)
fc$find_implications()
fc$implications
```

** Keep in mind that the find_implications() is based in the use of the algorithm `NextClosure` in formal concepts to extract implication basis.

3. From the implications set, we could simplify using logic operations like reduction, composition, generalization or simplification rules.

```{r simplification}
fc$implications$apply_rules(c("composition","generalization","simplification","reduction"))
```

# Use of the Direct-Optimal basis 

## Direct-Optimal Basis Basic Algorithm

It is recommended, to understand more in depth the mathematical concepts of this algorithm, look at the article:

> Estrella Rodríguez-Lorenzo, Karell Bertet, Pablo Cordero, Manuel Enciso, Ángel Mora (Available online 8 April 2018)
"Direct-optimal basis computation by means of the fusion of simplification rules"

Published in https://www.sciencedirect.com/science/article/abs/pii/S0166218X1730611X

The algorithm is based in the use of three functions:

** In all of the functions of this algorithm, is given an argument &Sigma;. In the article &Sigma; is expressed like a implications set, but in the script is expressed like a couple of sparse matrix (lhs and rhs) that shows in each column, the column number together with 1s in the positions where each attribute appears, respectly, as much in the left side (lhs) as in the right side (rhs).

```{r basis}
fc$implications
fc$implications[1]
fc$implications$get_LHS_matrix()
fc$implications$get_RHS_matrix()
Matrix(fc$implications$get_LHS_matrix()[,1], sparse = TRUE)
Matrix(fc$implications$get_RHS_matrix()[,1], sparse = TRUE)
```

### Add_sSimp function

The ".add_sSimp(A, B, C, D, sigma_lhs, sigma_rhs)" function takes as parameters two implications (in the script implemented as 4 columns sparse matrix) and the implications set &Sigma;, and it returns a set with an implication or an empty set and a flag that we explain its use after the next function. In this case, the flag checks if the resultant implication is the combination between the left and the right part of the implications passed in the arguments, and it activates or desactivates if it occurs.

<center><img src="../docs/images/dob_add_sSimp.png" alt="drawing" width="400"/></center>

### Simplify function

The ".simplifyDOB(sigma_lhs, sigma_rhs, attr)" function takes as parameter &Sigma; and the attributes, and it returns an simplified implications set equivalent to &Sigma;. It is important to remark that, in the script of this function and the next one, it is implemented a flag system to do the equality operation in the until section more efficient instead of checking the two sets using an brute force algorithm. The motive of the use of these flags is explained in the next function.

<center><img src="../docs/images/dob_simplify_DOB.png" alt="drawing" width="400"/></center>

### Direct-Optimal Basis algorithm (SLgetdo Function)

The ".slGetDo(sigma_lhs, sigma_rhs, attr)" function takes as parameter &Sigma; and the attributes, and it returns an simplified implications set equivalent to &Sigma;. This function use the two previous mentioned functions. 

<center><img src="../docs/images/dob_SL_Get_DO.png" alt="drawing" width="400"/></center>

** We have to add that we use auxiliary functions to make operations between sets like .union(A,B), .difference2(A,B), ... (Implemented base). Nevertheless, for this algorithm, it was developed two auxiliary functions more:

  a) <b> A function to compare two column matrix (.columnEquals(A,B)) </b> (Important!: we don't have to use to compare sets of cardinality greater than one, since in a set doesn't     influence the order, so {a,b} = {b,a} and this feature is very inefficient to make with an brute-force algorithm), so we implement, in simplify and in SLgetdo, a flag system to     do the equality.
  
  b) <b> A function to compare two matrix (.matrixEquals(A,B)) </b> (Important!: this function, due as the mentioned comment in the previous point, is only used to test the      algorithm before applying the flags, to check the algorithm performance.)

Example to see the performance (Obtained from the article in the introduction).

1) First, we check the input and the output of the algorithm.

```{r SLgetdo_1}
# Input
input <- system.file("Implications", "ex_implicationsDOB", package = "fcaR")
imp_in <- parse_implications(input)
imp_in

# Output
output <- system.file("Implications", "ex_implicationsDOB_sol", package = "fcaR")
imp_out <- parse_implications(output)
imp_out

# We have to prepare the data because the order of the attributes is incorrect.
# Correct input.
attrSorted <- sort(imp_in$get_attributes())
sigma_lhs_Sorted <- imp_in$get_LHS_matrix()[attrSorted,]
sigma_rhs_Sorted <- imp_in$get_RHS_matrix()[attrSorted,]
imp_in_ex_DOB <- ImplicationSet$new(lhs=sigma_lhs_Sorted, rhs=sigma_rhs_Sorted, attributes = attrSorted )

# Correct output
attrSorted <- sort(imp_out$get_attributes())
sigma_lhs_Sorted <- imp_out$get_LHS_matrix()[attrSorted,]
sigma_rhs_Sorted <- imp_out$get_RHS_matrix()[attrSorted,]
imp_out_ex_DOB <- ImplicationSet$new(lhs=sigma_lhs_Sorted, rhs=sigma_rhs_Sorted, attributes = attrSorted )

```

2) Now, we introduce the input to the algorithm to check that it is equivalent to the output.
(It is important to know that the basis do not have to be the same.)

```{r SLgetdo_2}
sigma_lhs <- imp_in_ex_DOB$get_LHS_matrix()
sigma_rhs <- imp_in_ex_DOB$get_RHS_matrix()
attr <- imp_in_ex_DOB$get_attributes()

imp_simp <- .slGetDo(sigma_lhs,sigma_rhs,attr)
res <- ImplicationSet$new(attributes = attr, lhs = imp_simp[[1]], rhs = imp_simp[[2]])
res

# Función para comparar equivalencia 
paste("The equivalence between the solution of the algorithm and the paper is: ",  res %~% imp_out_ex_DOB,sep="")
```

  \*\* <i>If it requires to see more examples, in the test section of the proyect
  "../tests/testthat/test-algorithm-DOB.R" there are more test.</i>

## More efficient algorithm (Fast Direct-Optimal Basis)

It is recommended, to understand more in depth the mathematical concepts of this algorithm, look at the article:

> Estrella Rodríguez-Lorenzo, Kira Adaricheva, Pablo Cordero, Manuel Enciso &
Angel Mora (2017) Formation of the D-basis from implicational systems using Simplification logic,
International Journal of General Systems, 46:5, 547-568, DOI: 10.1080/03081079.2017.1349632

Published in https://www.tandfonline.com/doi/full/10.1080/03081079.2017.1349632

The algorithm is based in the use of 6 functions:

** In all of the functions of this algorithm, it takes as parameter &Gamma;. In the article &Gamma; is expressed as a set that contains vectors like <X,Y,Z> where each element is an attributes set, but in the script &Gamma; is expressed like a sparse matrix where each column express an attributes set, for example: X<sub>1</sub>, Y<sub>1</sub>, Z<sub>1</sub>, X<sub>2</sub>, Y<sub>2</sub>, Z<sub>2</sub>, ...

### AddClosure function

The addClosure function takes as parameters an attributes set A and a set &Gamma; and it returns a 3-tuple of three attributes sets.

<center><img src="../docs/images/fdob_addClosure.png" alt="drawing" width="500"/></center>

### Fix function

The fix function takes as parameters a 3-tuple of three attributes sets and a set &Gamma;, and it returns a list with a minimals set and a set &Gamma;<sub>new</sub>.

<center><img src="../docs/images/fdob_fix.png" alt="drawing" width="500"/></center>

### Shorten function

The shorten function takes as parameters a 3-tuple of three attributes sets and a set &Gamma;, and it returns a new 3-tuple (if the set A have cardinality different to 1) or the same 3-tuple in other case.

<center><img src="../docs/images/fdob_shorten.png" alt="drawing" width="400"/></center>

### Join function

The join function takes as parameters two sets &Gamma; and it returns the union of the two sets, but simplified by the shorten function.

<center><img src="../docs/images/fdob_join.png" alt="drawing" width="500"/></center>

### MinCovers function

The mincovers function takes as parameters a 3-tuple of attributes and a set &Gamma; and it returns a set &Phi;.

<center><img src="../docs/images/fdob_minCovers.png" alt="drawing" width="400"/></center>

### Fast-DBasis function

The .algorithm_FDB function takes as parameters am implications set &Sigma; and it returns a list with two implications set (One with all the implications with cardinality 1 &Sigma;<sub>bin</sub>, and the other without them &Sigma;<sub>n</sub>)

<center><img src="../docs/images/fdob_algorithm.png" alt="drawing" width="600"/></center>

Example to see the functioning (Obtained from the article in the introduction).

1) First, we check the input and the output of the algorithm.

```{r FastD-Basis_1}
# Input
# Input
input <- system.file("Implications", "ex_implicationsFDOB", package = "fcaR")
imp_in <- parse_implications(input)
imp_in

# Output
output <- system.file("Implications", "ex_implicationsFDOB_sol", package = "fcaR")
imp_out <- parse_implications(output)
imp_out

```

2) Now, we introduce the input to the algorithm to check that it is equals.

```{r FastD-Basis_2}
sigma_lhs <- imp_in$get_LHS_matrix()
sigma_rhs <- imp_in$get_RHS_matrix()
attr <- imp_in$get_attributes()
 
imp_simp <- .algorithm_FDB(sigma_lhs, sigma_rhs, attr)
res <- ImplicationSet$new(lhs=cbind(imp_simp[[1]],imp_simp[[3]]), rhs=cbind(imp_simp[[2]],imp_simp[[4]]), attributes = attr )

# Función para comparar equivalencia 
paste("The equivalence between the solution of the algorithm and the paper is: ",  res %~% imp_out,sep="")
```

  \*\* <i>If it requires to see more examples, in the test section of the proyect
  "../tests/testthat/test-algorithm-DOB.R" there are more test.</i>
